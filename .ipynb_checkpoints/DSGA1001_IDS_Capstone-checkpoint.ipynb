{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxuafRGmgOf_"
   },
   "source": [
    "# Part I. Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GmwQIMOWuUIF"
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, LassoCV, RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KernelDensity, NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "672GjwXMudEx",
    "outputId": "722a36e5-011c-4bd0-9591-55eb1e308765"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#import csv file to colab\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#reference site: https://pythonviz.com/colab-jupyter/google-colab-notebook-file-io-csv-input-output/\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      4\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "#import csv file to colab\n",
    "#reference site: https://pythonviz.com/colab-jupyter/google-colab-notebook-file-io-csv-input-output/\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GjGXx5tSudqh"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/Data/Medicalpremium.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RipEunJ41oxx",
    "outputId": "02c24fc5-d8b4-4c71-97da-5fe4ae55978c"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "LC0m-C9h3deH",
    "outputId": "ca58d48b-3131-4e35-f528-3bbc041969f9"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6qfyeEngX6q",
    "outputId": "050b64ef-39c5-420a-f343-ccfbca4a4e9e"
   },
   "outputs": [],
   "source": [
    "#Test for Normality\n",
    "# Perform Shapiro-Wilk Test.\n",
    "from scipy.stats import shapiro \n",
    "for col in df:\n",
    "    print(col)\n",
    "    s,p = shapiro(df.loc[:col])\n",
    "    print(s,round(p,4))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "rVUcAndt5TkI",
    "outputId": "d130fd65-2830-42a5-d6cc-a0b3af588ce6"
   },
   "outputs": [],
   "source": [
    "df.corr(method='spearman')\n",
    "#df.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "V3liAeGB81lv",
    "outputId": "6722c599-ac72-4f3f-ce7b-f2e396383d89"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(df.corr(method='pearson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "KJpsK1-Yf6ZM",
    "outputId": "1ea8f8a7-52e1-4647-eda4-630a3d8f920f"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(method='spearman'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GcjaQUV1Q0sO",
    "outputId": "c04427a7-ef0d-43cb-d10e-96f4d672bd7c"
   },
   "outputs": [],
   "source": [
    "# Compute Spearmann Correlation Coefficient (r) for each pair of variables\n",
    "# Compute Pearson Correlation Coefficient (r) for each pair of variables\n",
    "for col1 in df:\n",
    "    corr_df = pd.DataFrame(columns = ['r', 'p'])\n",
    "    for col2 in df:\n",
    "        r , p = stats.spearmanr(df[col1], df[col2])\n",
    "        #r , p = stats.pearsonr(df[col1], df[col2])\n",
    "        corr_df.loc[col2] = [round(r,4),round(p,4)]\n",
    "    print()\n",
    "    print(col1)\n",
    "    print(corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QT0CgWCI1RuG",
    "outputId": "cfeeae04-a844-49b6-aad1-74f33664b948"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,r2_score, mean_squared_error\n",
    "import random\n",
    "scale = StandardScaler()\n",
    "scaled = pd.DataFrame(scale.fit_transform(df))\n",
    "\n",
    "random = random.seed(15020304) #N-number: \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled.iloc[:,:-1], scaled.iloc[:,-1], train_size=0.8,random_state=random)\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "# LassoCV\n",
    "lasso = LassoCV()\n",
    "lasso.fit(x_train, y_train)\n",
    "print(f'Optimal alpha: {lasso.alpha_}')\n",
    "\n",
    "coef = dict()\n",
    "for i in range(10):\n",
    "  coef[df.columns[i]] = lasso.coef_[i]\n",
    "print(f'coefficeints:\\n{coef}')\n",
    "\n",
    "y_pred = lasso.predict(x_test)\n",
    "print(f'R^2: {lasso.score(x_test, y_test)}')\n",
    "r2_lasso= lasso.score(x_test, y_test)\n",
    "rmse_lasso = np.sqrt(mean_absolute_error(y_test,y_pred))\n",
    "print(f'RMSE: {rmse_lasso}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEAeg6pRZSPf"
   },
   "source": [
    "# Part II. Inference \n",
    "\n",
    "---\n",
    "\n",
    "The motivation is to identify whether the premium price varies depending on certain variables. For example, I want to find if the premium price differs for customers with diabetes and customers without diabetes. To do so, I split the distribution into people with diabetes and people without diabetes, and use Welche's t-test to calculate the p-value. Using the alpha level of .05, I assess whether to reject or fail to reject the null hypothesis, which assumes that there is no difference in the distribution of the two group.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWvnMEThJm1C"
   },
   "outputs": [],
   "source": [
    "def effect_size(df1, df2):\n",
    "    std = np.sqrt(((df1.count() - 1)*df1.std()**2 + (df2.count() - 1)*df2.std()**2 )/(df1.count() + df2.count()))\n",
    "    return (df1.mean() - df2.mean())/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PAsIlnIpJpPA"
   },
   "outputs": [],
   "source": [
    "alpha=.05\n",
    "power=.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qi4LsFapZbN4"
   },
   "outputs": [],
   "source": [
    "# Standardized premium price column\n",
    "df['PremiumPrice']=(df['PremiumPrice']-df['PremiumPrice'].mean())/df['PremiumPrice'].std()\n",
    "\n",
    "# Divide the distribution into two category. I divided into: \n",
    "# - people with diabetes or without diabetes,\n",
    "# - people with ages above 50 and ages under 50, \n",
    "# - people with and without chronic disease, \n",
    "# - people who had no surgery and people with surgeries more than or equal to 1. \n",
    "\n",
    "diabetes_1 = df[(df['Diabetes'] == 1)]['PremiumPrice']\n",
    "diabetes_0 = df[(df['Diabetes'] == 0)]['PremiumPrice']\n",
    "\n",
    "age_above50 = df[df['Age'] >= 50]['PremiumPrice']\n",
    "age_below50 = df[df['Age'] < 50]['PremiumPrice']\n",
    "\n",
    "chronicDisease_1 = df[df['AnyChronicDiseases'] == 1]['PremiumPrice']\n",
    "chronicDisease_0 = df[df['AnyChronicDiseases'] == 0]['PremiumPrice']\n",
    "\n",
    "had_surgeries = df[df['NumberOfMajorSurgeries'] > 0]['PremiumPrice']\n",
    "no_surgery = df[df['NumberOfMajorSurgeries'] == 0]['PremiumPrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aoq_v9pWf1Fq"
   },
   "source": [
    "Surgery distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hEyELyRfJ6_1",
    "outputId": "09f5c41f-d0ba-4188-ad60-2d2ac8130e98"
   },
   "outputs": [],
   "source": [
    "# Power Analysis\n",
    "effect_size_surgery = effect_size(had_surgeries, no_surgery)\n",
    "\n",
    "# Perform power analysis to find sample size for given effect\n",
    "obj = TTestIndPower()\n",
    "n = obj.solve_power(effect_size=effect_size_surgery, alpha=alpha, power=power, \n",
    "                    ratio=1, alternative='two-sided')\n",
    "  \n",
    "print('Sample size/Number needed in each group: {:.3f}'.format(n))\n",
    "\n",
    "had_surgeries.count(), no_surgery.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "jcvEZsB2blLm",
    "outputId": "b227e846-55c2-45e6-a394-d45e1d43c11a"
   },
   "outputs": [],
   "source": [
    "plt.subplots(1, 1, figsize=(10,6))\n",
    "        \n",
    "plt.hist(had_surgeries.values, alpha=.65, label='had more than one surgery', density=True)\n",
    "plt.hist(no_surgery.values, alpha=.5, label='had no surgery', density=True)\n",
    "\n",
    "mean1 = had_surgeries.values.mean()\n",
    "mean0 = no_surgery.values.mean()\n",
    "\n",
    "plt.vlines(mean1, 0, 1, color='navy', ls='--', label='Mean premium price for surgery > 0')\n",
    "plt.vlines(mean0, 0, 1, color='red', ls='--', label='Mean premium price for no surgery')\n",
    "\n",
    "ci_no_surgery = stats.t.interval(1 - alpha, len(no_surgery) - 1, loc=np.mean(no_surgery), scale=stats.sem(no_surgery))\n",
    "ci_surgery = stats.t.interval(1 - alpha, len(had_surgeries) - 1, loc=np.mean(had_surgeries), scale=stats.sem(had_surgeries))\n",
    "\n",
    "plt.vlines(ci_no_surgery[0], 0, 1, color='yellow', ls='--', label='Confidence Interval 95%')\n",
    "plt.vlines(ci_no_surgery[1], 0, 1, color='yellow', ls='--')\n",
    "\n",
    "plt.vlines(ci_surgery[0], 0, 1, color='yellow', ls='--')\n",
    "plt.vlines(ci_surgery[1], 0, 1, color='yellow', ls='--')\n",
    "\n",
    "plt.xlabel('Premium price')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Premium price distribution based on surgery history')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VJxNEE8-fH_r",
    "outputId": "e77d325e-07ac-4a16-f5fa-f93d709eb70b"
   },
   "outputs": [],
   "source": [
    "statistics, pval = stats.ttest_ind(no_surgery, had_surgeries, equal_var=False)\n",
    "print(\"The p-value from using Welche's t-test is: \", pval)\n",
    "s = (\"Since our p-value is under the alpha level, \\n\" \n",
    "    \"we deem the result to be statistically significant\" \n",
    "    \"and thus we reject the null hypothesis. \\n\\n\"\n",
    "    \"There is a difference in premium price based on surgery history.\")\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXhoV6bof8k7"
   },
   "source": [
    "Diabetes distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ElKMkUC6KBlq",
    "outputId": "00201b8d-ce36-42ba-9d5c-475a3a2cc8e6"
   },
   "outputs": [],
   "source": [
    "# Power Analysis\n",
    "effect_size_diabete = effect_size(diabetes_1, diabetes_0)\n",
    "\n",
    "# Perform power analysis to find sample size for given effect\n",
    "obj = TTestIndPower()\n",
    "n = obj.solve_power(effect_size=effect_size_diabete, alpha=alpha, power=power, \n",
    "                    ratio=1, alternative='two-sided')\n",
    "  \n",
    "print('Sample size/Number needed in each group: {:.3f}'.format(n))\n",
    "print('Sample size of each group: {:.3f}, {:.3f}'.format(diabetes_1.count(), diabetes_0.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "4wC9YdM9fe9m",
    "outputId": "e8ae8167-fdf3-4d88-d483-cb2114aa70e5"
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.subplots(1, 1, figsize=(10,6))\n",
    "        \n",
    "plt.hist(diabetes_1.values, alpha=.65, label='diabetes', density=True)\n",
    "plt.hist(diabetes_0.values, alpha=.5, label='non-diabetes', density=True)\n",
    "\n",
    "mean1 = diabetes_1.values.mean()\n",
    "mean0 = diabetes_0.values.mean()\n",
    "\n",
    "plt.vlines(mean1, 0, 1, color='navy', ls='--', label='Mean premium price for diabetes')\n",
    "plt.vlines(mean0, 0, 1, color='red', ls='--', label='Mean premium price for non-diabetes')\n",
    "\n",
    "ci_diabetes = stats.t.interval(1 - alpha, len(diabetes_1) - 1, loc=np.mean(diabetes_1), scale=stats.sem(diabetes_1))\n",
    "ci_no_diabetes = stats.t.interval(1 - alpha, len(diabetes_0) - 1, loc=np.mean(diabetes_0), scale=stats.sem(diabetes_0))\n",
    "\n",
    "plt.vlines(ci_diabetes[0], 0, 1, color='yellow', ls='--', label='Confidence Interval 95%')\n",
    "plt.vlines(ci_diabetes[1], 0, 1, color='yellow', ls='--')\n",
    "\n",
    "plt.vlines(ci_no_diabetes[0], 0, 1, color='yellow', ls='--')\n",
    "plt.vlines(ci_no_diabetes[1], 0, 1, color='yellow', ls='--')\n",
    "\n",
    "plt.xlabel('Premium price')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Premium price distribution based on diabete status')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AaWbWpTpfioi",
    "outputId": "5b301719-98e1-4838-9e38-0ef3c7ad1f69"
   },
   "outputs": [],
   "source": [
    "statistics, pval = stats.ttest_ind(diabetes_1, diabetes_0, equal_var=False)\n",
    "pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvi0a1aqf_ZK"
   },
   "source": [
    "Age distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nEuJlvelKIMn",
    "outputId": "4a6edbc5-fb20-455f-d5d9-f4d6249d193c"
   },
   "outputs": [],
   "source": [
    "# Power Analysis\n",
    "effect_size_age = effect_size(age_above50, age_below50)\n",
    "\n",
    "# Perform power analysis to find sample size for given effect\n",
    "obj = TTestIndPower()\n",
    "n = obj.solve_power(effect_size=effect_size_age, alpha=alpha, power=power, \n",
    "                    ratio=1, alternative='two-sided')\n",
    "  \n",
    "print('Sample size/Number needed in each group: {:.3f}'.format(n))\n",
    "print('Sample size of each group: {:.3f}, {:.3f}'.format(age_above50.count(), age_below50.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "8iuahbUZflXc",
    "outputId": "c4923c53-988c-4c2e-995d-3ee5e6a6f64c"
   },
   "outputs": [],
   "source": [
    "plt.subplots(1, 1, figsize=(10,6))\n",
    "        \n",
    "plt.hist(age_above50.values, alpha=.65, label='age above 50', density=True)\n",
    "plt.hist(age_below50.values, alpha=.5, label='age below 50', density=True)\n",
    "\n",
    "mean1 = age_above50.values.mean()\n",
    "mean0 = age_below50.values.mean()\n",
    "\n",
    "plt.vlines(mean1, 0, 1, color='navy', ls='--', label='Mean premium price for age above 50')\n",
    "plt.vlines(mean0, 0, 1, color='red', ls='--', label='Mean premium price for age below 50')\n",
    "\n",
    "ci_age_above50 = stats.t.interval(1 - alpha, len(age_above50) - 1, loc=np.mean(age_above50), scale=stats.sem(age_above50))\n",
    "ci_age_below50 = stats.t.interval(1 - alpha, len(age_below50) - 1, loc=np.mean(age_below50), scale=stats.sem(age_below50))\n",
    "\n",
    "plt.vlines(ci_age_above50[0], 0, 1, color='yellow', ls='--', label='Confidence Interval 95%')\n",
    "plt.vlines(ci_age_above50[1], 0, 1, color='yellow', ls='--')\n",
    "\n",
    "plt.vlines(ci_age_below50[0], 0, 1, color='yellow', ls='--')\n",
    "plt.vlines(ci_age_below50[1], 0, 1, color='yellow', ls='--')\n",
    "\n",
    "plt.xlabel('Premium price')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Premium price distribution based on age')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZrOo79hTfnqi",
    "outputId": "b8b1a408-cca1-4536-9a79-42331c7b2b3e"
   },
   "outputs": [],
   "source": [
    "statistics, pval = stats.ttest_ind(age_above50, age_below50, equal_var=False)\n",
    "pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5V9k93fwgB2d"
   },
   "source": [
    "Chronic disease distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjxzwJt-KK_a",
    "outputId": "5e9294f0-b1c5-43c2-ea2d-99068384264b"
   },
   "outputs": [],
   "source": [
    "# Power Analysis\n",
    "effect_size_chronic = effect_size(chronicDisease_1, chronicDisease_0)\n",
    "\n",
    "# Perform power analysis to find sample size for given effect\n",
    "obj = TTestIndPower()\n",
    "n = obj.solve_power(effect_size=effect_size_chronic, alpha=alpha, power=power, \n",
    "                    ratio=1, alternative='two-sided')\n",
    "  \n",
    "print('Sample size/Number needed in each group: {:.3f}'.format(n))\n",
    "print('Sample size of each group: {:.3f}, {:.3f}'.format(chronicDisease_1.count(), chronicDisease_0.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "AWaVomKzfp0O",
    "outputId": "1481c1e7-8d5b-45bb-d134-b289042ce512"
   },
   "outputs": [],
   "source": [
    "plt.subplots(1, 1, figsize=(10,6))\n",
    "        \n",
    "plt.hist(chronicDisease_1.values, alpha=.65, label='has chronic disease', density=True)\n",
    "plt.hist(chronicDisease_0.values, alpha=.5, label='does not have chronic disease', density=True)\n",
    "\n",
    "mean1 = chronicDisease_1.values.mean()\n",
    "mean0 = chronicDisease_0.values.mean()\n",
    "\n",
    "plt.vlines(mean1, 0, 1, color='navy', ls='--', label='Mean premium price for people with chronic disease')\n",
    "plt.vlines(mean0, 0, 1, color='red', ls='--', label='Mean premium price for people without chronic disease')\n",
    "\n",
    "ci_chronicDisease_1 = stats.t.interval(1 - alpha, len(chronicDisease_1) - 1, loc=np.mean(chronicDisease_1), scale=stats.sem(chronicDisease_1))\n",
    "ci_chronicDisease_0 = stats.t.interval(1 - alpha, len(chronicDisease_0) - 1, loc=np.mean(chronicDisease_0), scale=stats.sem(chronicDisease_0))\n",
    "\n",
    "plt.vlines(ci_chronicDisease_1[0], 0, 1, color='yellow', ls='--', label='Confidence Interval 95%')\n",
    "plt.vlines(ci_chronicDisease_1[1], 0, 1, color='yellow', ls='--')\n",
    "\n",
    "plt.vlines(ci_chronicDisease_0[0], 0, 1, color='yellow', ls='--')\n",
    "plt.vlines(ci_chronicDisease_0[1], 0, 1, color='yellow', ls='--')\n",
    "\n",
    "plt.xlabel('Premium price')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Premium price distribution based on presence of chronic disease')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWemRgZrfsXJ",
    "outputId": "c014ff4d-c14f-40a1-ece7-c259043bf1d7"
   },
   "outputs": [],
   "source": [
    "statistics, pval = stats.ttest_ind(chronicDisease_1, chronicDisease_0, equal_var=False)\n",
    "pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRkiHhPm8aSI"
   },
   "source": [
    "# Part III. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_vemCsj38kSv"
   },
   "outputs": [],
   "source": [
    "#Reference: https://machinelearninghd.com/ridgecv-regression-python/\n",
    "#Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge, ElasticNet, LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WG38dAPN_cHs"
   },
   "source": [
    "Checking the data, if there is multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "S3KlN9ET8kXX",
    "outputId": "9475b0c1-c791-4dc0-adba-e6ae087f2eea"
   },
   "outputs": [],
   "source": [
    "#Checking the data, if there is multicollinearity.\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.heatmap(df.corr(),annot=True,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "L5-jqDYnLGVS",
    "outputId": "365dc1b8-4fed-49e1-f45f-3c57f4e66b90"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,r2_score, mean_squared_error\n",
    "import random\n",
    "scale = StandardScaler()\n",
    "scaled = pd.DataFrame(scale.fit_transform(df))\n",
    "\n",
    "random = random.seed(15020304) #N-number: \n",
    "\n",
    "# x_feature = pd.concat([scaled.iloc[:,0:5],scaled.iloc[:,6:-1]],axis=1) #eliminate height\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled.iloc[:,:-1], scaled.iloc[:,-1], train_size=0.8,random_state=random) #all features\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_feature, scaled.iloc[:,-1], train_size=0.8,random_state=random)\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "# LassoCV\n",
    "lasso = LassoCV()\n",
    "lasso.fit(x_train, y_train)\n",
    "print(f'Optimal alpha: {lasso.alpha_}')\n",
    "\n",
    "coef = dict()\n",
    "for i in range(10):\n",
    "  coef[df.columns[i]] = lasso.coef_[i]\n",
    "print(f'coefficeints:\\n{coef}')\n",
    "\n",
    "y_pred = lasso.predict(x_test)\n",
    "\n",
    "print(f'R^2: {lasso.score(x_test, y_test)}')\n",
    "r2_lasso= lasso.score(x_test, y_test)\n",
    "rmse_lasso = np.sqrt(mean_absolute_error(y_test,y_pred))\n",
    "print(f'RMSE: {rmse_lasso}')\n",
    "\n",
    "# print(f'R^2: {lasso.score(x_test, y_test)}')\n",
    "# r2_lasso_2= lasso.score(x_test, y_test)\n",
    "# rmse_lasso_2 = np.sqrt(mean_absolute_error(y_test,y_pred))\n",
    "# print(f'RMSE: {rmse_lasso}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IAeCju7r9HW7"
   },
   "outputs": [],
   "source": [
    "# define evaluation\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0erGgZmU9Hc5",
    "outputId": "598e7523-8c15-4394-b4ff-a59f67d1e4b7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,r2_score, mean_squared_error\n",
    "\n",
    "#Define Ridge Regression Model\n",
    "# define model\n",
    "model = Ridge()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "#Predicting the Model\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "#Evaluating the model\n",
    "coef_ridge = model.coef_\n",
    "r2_ridge = r2_score(y_test,y_pred)\n",
    "rmse_ridge = np.sqrt(mean_absolute_error(y_test,y_pred))\n",
    "print(f'R^2:{r2_score(y_test,y_pred)}')\n",
    "print(f'coefficeints:\\n{coef_ridge}')\n",
    "print(f'RMSE:{rmse_ridge}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fyq9Uu2Z9TfL"
   },
   "outputs": [],
   "source": [
    "#Find the best parameters through GridsearchCV\n",
    "#define parameters\n",
    "param = {\n",
    "    # 'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'alpha':np.arange(0.00001, 20, 0.1),\n",
    "    'fit_intercept':[True,False],\n",
    "    # 'normalize':[True,False],\n",
    "'solver':['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "LV-phV4z9TiU",
    "outputId": "d63779a1-0dc0-4325-a2dd-c5c2620c7d76"
   },
   "outputs": [],
   "source": [
    "#define model\n",
    "model = Ridge()\n",
    "\n",
    "# define search\n",
    "search = GridSearchCV(model, param, scoring='r2', n_jobs=-1, cv=cv)\n",
    "# execute search\n",
    "result = search.fit(x_train, y_train)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZnLNdKF_9TlL",
    "outputId": "09f7d82b-68d9-4748-a9bc-a962bfbb8f32"
   },
   "outputs": [],
   "source": [
    "model = Ridge(alpha=result.best_params_['alpha'],fit_intercept = result.best_params_['fit_intercept'], solver = result.best_params_['solver'])\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "coef_ridge = model.coef_\n",
    "r2_ridge = r2_score(y_test,y_pred)\n",
    "rmse_ridge = np.sqrt(mean_absolute_error(y_test,y_pred))\n",
    "print(f'R^2:{r2_score(y_test,y_pred)}')\n",
    "print(f'coefficeints:\\n{coef_ridge}')\n",
    "print(f'RMSE:{rmse_ridge}')\n",
    "\n",
    "# r2_ridge_2 = r2_score(y_test,y_pred)\n",
    "# rmse_ridge_2 = np.sqrt(mean_absolute_error(y_test,y_pred))\n",
    "# print(f'R^2:{r2_score(y_test,y_pred)}')\n",
    "# print(f'coefficeints:\\n{coef_ridge}')\n",
    "# print(f'RMSE:{np.sqrt(mean_absolute_error(y_test,y_pred))}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Mt8DrBNs08xL",
    "outputId": "a763de1a-e03b-4906-ceca-b0713ededcbd"
   },
   "outputs": [],
   "source": [
    "#Elastic Net\n",
    "model = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "coef_elas = model.coef_\n",
    "r2_elas = r2_score(y_test,y_pred)\n",
    "rmse_elas = np.sqrt(mean_absolute_error(y_test,y_pred))\n",
    "print(f'R^2:{r2_elas}')\n",
    "print(f'coefficeints:\\n{coef_elas}')\n",
    "print(f'RMSE:{rmse_elas}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "l28LFv2U7Z3p",
    "outputId": "a38f3ee3-15f8-4efa-8eeb-a224af073f08"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "parametersGrid = {\"max_iter\": [1, 5, 10],\n",
    "                  'alpha':np.arange(0.00001, 20, 0.1),\n",
    "                      # \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                      \"l1_ratio\": np.arange(0.0, 1.0, 0.1)}\n",
    "\n",
    "grid = GridSearchCV(model, parametersGrid, scoring='r2', cv=10)\n",
    "grid.fit(x_train, y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "n-HaFKyo90hb",
    "outputId": "87cd3f60-6f53-46dc-f37e-b2500cacb315"
   },
   "outputs": [],
   "source": [
    "#Elastic Net\n",
    "model = ElasticNet(alpha=grid.best_params_['alpha'], l1_ratio=grid.best_params_['l1_ratio'])\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "coef_elas = model.coef_\n",
    "# r2_elas = r2_score(y_test,y_pred)\n",
    "# rmse_elas = np.sqrt(mean_absolute_error(y_test,y_pred))\n",
    "# print(f'R^2:{r2_elas}')\n",
    "# print(f'coefficeints:\\n{coef_elas}')\n",
    "# print(f'RMSE:{rmse_elas}')\n",
    "\n",
    "\n",
    "r2_elas_2 = r2_score(y_test,y_pred)\n",
    "rmse_elas_2 = np.sqrt(mean_absolute_error(y_test,y_pred))\n",
    "print(f'R^2:{r2_score(y_test,y_pred)}')\n",
    "print(f'coefficeints:\\n{coef_elas}')\n",
    "print(f'RMSE:{np.sqrt(mean_absolute_error(y_test,y_pred))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Q5hTPUlTKSS0"
   },
   "outputs": [],
   "source": [
    "model_assessment = pd.DataFrame(columns=df.columns[:-1])\n",
    "model_assessment.loc['Lasso'] = coef\n",
    "model_assessment.loc['Ridge'] = coef_ridge\n",
    "model_assessment.loc['ElasticNet'] = coef_elas\n",
    "model_assessment['R^2'] = [r2_lasso,r2_ridge,r2_elas]\n",
    "model_assessment['RMSE'] = [rmse_lasso,rmse_ridge,rmse_elas]\n",
    "model_assessment = model_assessment.round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "78mjn13wj9np",
    "outputId": "0e03d035-9439-4d19-b381-344f8aa8727e"
   },
   "outputs": [],
   "source": [
    "model_assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "B42O2t9PjCcZ"
   },
   "outputs": [],
   "source": [
    "model_assessment.to_csv('/content/drive/MyDrive/Data/model_assessment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "XbPMKwimlF9P",
    "outputId": "2a0bb2ee-7607-4ba7-cb94-7dea620a5ea0"
   },
   "outputs": [],
   "source": [
    "model_assessment2 = pd.DataFrame(index = ['Lasso', 'Ridge','Elastic Net'])\n",
    "model_assessment2['R^2'] = [r2_lasso,r2_ridge,r2_elas]\n",
    "model_assessment2['RMSE'] = [rmse_lasso,rmse_ridge,rmse_elas]\n",
    "model_assessment2['updated R^2'] = [r2_lasso_2,r2_ridge_2,r2_elas_2]\n",
    "model_assessment2['updated RMSE'] = [rmse_lasso_2,rmse_ridge_2,rmse_elas_2]\n",
    "model_assessment2 = model_assessment2.round(4)\n",
    "model_assessment2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "UM762f7qCd1l"
   },
   "outputs": [],
   "source": [
    "plt.scatter(['Lasso', 'Ridge', 'Elastic Net'], model_assessment2['R^2'], color='blue',label='R^2')\n",
    "plt.scatter(['Lasso', 'Ridge', 'Elastic Net'], model_assessment2['updated R^2'], color='orange',label='updated R^2')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIMpExBjiL1y"
   },
   "source": [
    "# Part IV. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "58qeApEJdUkJ"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, r2_score, confusion_matrix, ConfusionMatrixDisplay, precision_recall_curve, auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "W6t3a5bcdYvD"
   },
   "outputs": [],
   "source": [
    "s = StandardScaler()\n",
    "temp = df\n",
    "s.fit(temp[['Age', 'Height', 'Weight', 'PremiumPrice']])\n",
    "new = s.transform(temp[['Age', 'Height', 'Weight', 'PremiumPrice']]).T\n",
    "temp.Age = new[0]\n",
    "temp.Height = new[1]\n",
    "temp.Weight = new[2]\n",
    "temp.PremiumPrice = new[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3zVIS8iFefhS"
   },
   "outputs": [],
   "source": [
    "X_col = df.columns.drop('Diabetes')\n",
    "X = df[X_col]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, df.Diabetes, train_size=0.8, random_state=15020304)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "TJpxTLsbeIQB"
   },
   "outputs": [],
   "source": [
    "## Kaiser Criterion: Consider all principal components with eigen values greater than 1.0\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "eigval = pca.explained_variance_\n",
    "n = 10\n",
    "x = np.arange(1,11)\n",
    "plt.bar(x, eigval, color='navy', alpha=0.6)\n",
    "plt.hlines(1.0,0,11, color='orange')\n",
    "plt.xlabel('Principal component')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.xticks(ticks=x)\n",
    "plt.text(7,1.1,'Kaiser Criterion Line', color='orange')\n",
    "plt.show()\n",
    "print(f'Variance explained by the first 2 PC above is: {sum(pca.explained_variance_ratio_[:2])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "l-dCu0RzeM5S"
   },
   "outputs": [],
   "source": [
    "# Use Silhouette Score to find the optimal k for k-means\n",
    "opt_pca = PCA(n_components=2)\n",
    "newX = opt_pca.fit_transform(X)\n",
    "s = []\n",
    "for i in range(2,11):\n",
    "    kmeans = KMeans(n_clusters = i)\n",
    "    kmeans.fit(newX)\n",
    "    cID = kmeans.labels_\n",
    "    s.append(silhouette_score(newX, cID))\n",
    "\n",
    "plt.plot(np.arange(2,11), s)\n",
    "plt.xlabel('number of clusters for K-Means')\n",
    "plt.ylabel('mean silhouette score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ztaPQifGeRi5"
   },
   "outputs": [],
   "source": [
    "# optimize k-means with clusters of 2\n",
    "opt_kmeans = KMeans(n_clusters=2)\n",
    "opt_kmeans.fit(newX)\n",
    "labels = opt_kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "fdMZVJjUeUBy"
   },
   "outputs": [],
   "source": [
    "# plot premium by labels\n",
    "newX = newX.T\n",
    "sns.scatterplot(newX[0][np.where(labels==0)[0]],newX[1][np.where(labels==0)[0]])\n",
    "sns.scatterplot(newX[0][np.where(labels==1)[0]],newX[1][np.where(labels==1)[0]])\n",
    "\n",
    "plt.xlabel('principle component [1]')\n",
    "plt.ylabel('principle component [2]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "F2A1LuDLeVHN"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\": [3, 4, 5, 7],\n",
    "    \"learning_rate\": [0.1, 0.01, 0.05],\n",
    "    \"gamma\": [0, 0.25, 1],\n",
    "    \"reg_lambda\": [0, 1, 10],\n",
    "    \"scale_pos_weight\": [1, 3, 5],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.5]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(objective='binary:logistic')\n",
    "grid = GridSearchCV(xgb, param_grid, scoring='roc_auc')\n",
    "grid.fit(X, df.Diabetes)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "viq_5Hm6e2gc"
   },
   "outputs": [],
   "source": [
    "opt_xgb = XGBClassifier(objective='binary:logistic', **grid.best_params_)\n",
    "opt_xgb.fit(x_train, y_train)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, opt_xgb.predict(x_test))\n",
    "dsip = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[0,1])\n",
    "dsip.plot()\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "probs = opt_xgb.predict_proba(x_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "random_classifier=np.linspace(0.0, 1.0, 100)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, color=\"purple\")\n",
    "plt.plot(random_classifier, random_classifier, 'r--')\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.show()\n",
    "print(f'feature importance: {opt_xgb.feature_importances_} \\nArea under ROC curve: {auc(fpr, tpr)}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "JEAeg6pRZSPf"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
